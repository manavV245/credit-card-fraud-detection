{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615fadca",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Training/Testing/Evaluating Models \n",
    "\n",
    "## 0) Run the code cell below to start\n",
    "\n",
    "We begin with the many imports required for modelling (train/test split, performance metrics, and the models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bd7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    average_precision_score,\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb690629",
   "metadata": {},
   "source": [
    "## 1) Load Data \n",
    "\n",
    "We'll begin with splitting the data into features and the target\n",
    "\n",
    "The target is `Class` (0 = Real, 1 = Fraud). We'll split the data into `X` (features) and `y` (labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1d749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (284807, 30)\n",
      "y mean (fraud rate): 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/raw/creditcard.csv\"\n",
    "df = pd.read_csv(DATA_PATH) \n",
    "\n",
    "X = df.drop(columns=[\"Class\"]) \n",
    "y = df[\"Class\"] \n",
    "\n",
    "print(\"X shape:\", X.shape) \n",
    "print(\"y mean (fraud rate):\", y.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876ff2a",
   "metadata": {},
   "source": [
    "## 2) Stratified Train/Test Split \n",
    "\n",
    "The `stratify` parameter of sklearn's train_test_split ensures that the training and testing sets both have the same proportion of labels (i.e fraud). \n",
    "\n",
    "We stratify by `y` to preserve the fraud rate in both the train and test sets. \n",
    "\n",
    "This is very important for imbalanced data; small differences in the quantity of fraud in either set can lead to detrimental differences in the model's predictions between the training and testing sets. \n",
    "\n",
    "Stratifying ensures we properly test our model while still preserving any patterns for our model to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c029bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fraud rate: 0.001729245759178389\n",
      "Test fraud rate: 0.0017204452090867595\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train fraud rate:\", y_train.mean()) \n",
    "print(\"Test fraud rate:\", y_test.mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dec25",
   "metadata": {},
   "source": [
    "## 3) Evaluation Helper Function \n",
    "\n",
    "We'll evaluate our models using: \n",
    "- Confusion Matrix \n",
    "- Classification Report (precision/recall/F1) \n",
    "- ROC-AUC \n",
    "- PR-AUC (often more informative for imbalanced sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab7a0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te): \n",
    "    model.fit(X_tr, y_tr) \n",
    "\n",
    "    y_pred = model.predict(X_te) \n",
    "\n",
    "    # Since only some models support predict_proba, we have a handler \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    else: \n",
    "        y_score = None \n",
    "    \n",
    "    print(f\"\\n=== {name} ===\") \n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred)) \n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_te, y_pred, digits=4))\n",
    "\n",
    "    if y_score is not None: \n",
    "        roc = roc_auc_score(y_te, y_score) \n",
    "        pr = average_precision_score(y_te, y_score) \n",
    "        print(f\"ROC-AUC: {roc:.4f}\")\n",
    "        print(f\"PR-AUC (Average Precision): {pr:.4f}\") \n",
    "    else: \n",
    "        print(\"No probability scores available for ROC/PR-AUC\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a78ff",
   "metadata": {},
   "source": [
    "## 4) Baseline Model (DummyClassifier) \n",
    "\n",
    "This model will show why accuracy is very misleading. \n",
    "\n",
    "Our DummyClassifier will predict \"Real\" everytime, giving us a 99.83% accuracy (since 0.17% are fraud from our previous analysis), however, it will have a recall of 0 since it never flags any fraud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bdd4d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dummy Classifier ===\n",
      "Confusion Matrix:\n",
      " [[56864     0]\n",
      " [   98     0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9983    1.0000    0.9991     56864\n",
      "           1     0.0000    0.0000    0.0000        98\n",
      "\n",
      "    accuracy                         0.9983     56962\n",
      "   macro avg     0.4991    0.5000    0.4996     56962\n",
      "weighted avg     0.9966    0.9983    0.9974     56962\n",
      "\n",
      "ROC-AUC: 0.5000\n",
      "PR-AUC (Average Precision): 0.0017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\credit-card-fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\manav\\credit-card-fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\manav\\credit-card-fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\", random_state=42) \n",
    "evaluate_model(\"Dummy Classifier\", dummy, X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14488501",
   "metadata": {},
   "source": [
    "## 5) Logistic Regression \n",
    "\n",
    "A simple and strong baseline for binary classification. \n",
    "\n",
    "We will use `class_weight=\"balanced\"` to penalize missing fraud cases more heavily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eab612ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\credit-card-fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Confusion Matrix:\n",
      " [[55091  1773]\n",
      " [    8    90]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9688    0.9841     56864\n",
      "           1     0.0483    0.9184    0.0918        98\n",
      "\n",
      "    accuracy                         0.9687     56962\n",
      "   macro avg     0.5241    0.9436    0.5379     56962\n",
      "weighted avg     0.9982    0.9687    0.9826     56962\n",
      "\n",
      "ROC-AUC: 0.9719\n",
      "PR-AUC (Average Precision): 0.7309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\credit-card-fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000, \n",
    "    class_weight=\"balanced\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "evaluate_model(\"Logistic Regression\", log_reg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2fab77",
   "metadata": {},
   "source": [
    "## 6) Decision Tree\n",
    "\n",
    "Trees are a powerful and flexible tool as well, but they can be overfit. We'll start with a simple decision tree that we will later compare to XGBoosted trees in a future notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66054464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Decision Tree ===\n",
      "Confusion Matrix:\n",
      " [[56830    34]\n",
      " [   27    71]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9994    0.9995     56864\n",
      "           1     0.6762    0.7245    0.6995        98\n",
      "\n",
      "    accuracy                         0.9989     56962\n",
      "   macro avg     0.8379    0.8619    0.8495     56962\n",
      "weighted avg     0.9990    0.9989    0.9989     56962\n",
      "\n",
      "ROC-AUC: 0.8619\n",
      "PR-AUC (Average Precision): 0.4904\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "    random_state=42, \n",
    "    class_weight=\"balanced\", \n",
    "    max_depth=None\n",
    ") \n",
    "evaluate_model(\"Decision Tree\", tree, X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276a9ade",
   "metadata": {},
   "source": [
    "## 7) Conclusion & Next Notebook \n",
    "\n",
    "So far we have: \n",
    "- Built some baseline models that perform decently\n",
    "- used balanced class weightings to address the imabalanced data \n",
    "\n",
    "Next Notebook: \n",
    "- We will tune the decision threshold, optimizing for recall/precision \n",
    "- Look into SMOTE for imbalanced classification \n",
    "- Train and compare XGBoost using imbalanced tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc-fraud",
   "language": "python",
   "name": "cc-fraud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
